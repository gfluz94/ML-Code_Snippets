{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from itertools import permutations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Market_Basket_Optimisation.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>shrimp</td>\n",
       "      <td>almonds</td>\n",
       "      <td>avocado</td>\n",
       "      <td>vegetables mix</td>\n",
       "      <td>green grapes</td>\n",
       "      <td>whole weat flour</td>\n",
       "      <td>yams</td>\n",
       "      <td>cottage cheese</td>\n",
       "      <td>energy drink</td>\n",
       "      <td>tomato juice</td>\n",
       "      <td>low fat yogurt</td>\n",
       "      <td>green tea</td>\n",
       "      <td>honey</td>\n",
       "      <td>salad</td>\n",
       "      <td>mineral water</td>\n",
       "      <td>salmon</td>\n",
       "      <td>antioxydant juice</td>\n",
       "      <td>frozen smoothie</td>\n",
       "      <td>spinach</td>\n",
       "      <td>olive oil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>burgers</td>\n",
       "      <td>meatballs</td>\n",
       "      <td>eggs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>chutney</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>turkey</td>\n",
       "      <td>avocado</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>mineral water</td>\n",
       "      <td>milk</td>\n",
       "      <td>energy bar</td>\n",
       "      <td>whole wheat rice</td>\n",
       "      <td>green tea</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0          1           2                 3             4   \\\n",
       "0         shrimp    almonds     avocado    vegetables mix  green grapes   \n",
       "1        burgers  meatballs        eggs               NaN           NaN   \n",
       "2        chutney        NaN         NaN               NaN           NaN   \n",
       "3         turkey    avocado         NaN               NaN           NaN   \n",
       "4  mineral water       milk  energy bar  whole wheat rice     green tea   \n",
       "\n",
       "                 5     6               7             8             9   \\\n",
       "0  whole weat flour  yams  cottage cheese  energy drink  tomato juice   \n",
       "1               NaN   NaN             NaN           NaN           NaN   \n",
       "2               NaN   NaN             NaN           NaN           NaN   \n",
       "3               NaN   NaN             NaN           NaN           NaN   \n",
       "4               NaN   NaN             NaN           NaN           NaN   \n",
       "\n",
       "               10         11     12     13             14      15  \\\n",
       "0  low fat yogurt  green tea  honey  salad  mineral water  salmon   \n",
       "1             NaN        NaN    NaN    NaN            NaN     NaN   \n",
       "2             NaN        NaN    NaN    NaN            NaN     NaN   \n",
       "3             NaN        NaN    NaN    NaN            NaN     NaN   \n",
       "4             NaN        NaN    NaN    NaN            NaN     NaN   \n",
       "\n",
       "                  16               17       18         19  \n",
       "0  antioxydant juice  frozen smoothie  spinach  olive oil  \n",
       "1                NaN              NaN      NaN        NaN  \n",
       "2                NaN              NaN      NaN        NaN  \n",
       "3                NaN              NaN      NaN        NaN  \n",
       "4                NaN              NaN      NaN        NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7501/7501 [00:00<00:00, 7814.32it/s]\n"
     ]
    }
   ],
   "source": [
    "products = []\n",
    "\n",
    "for i in tqdm(range(df.shape[0])):\n",
    "    products.append([product.strip() for product in df.iloc[i, :].values if type(product)!=float])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7501/7501 [00:00<00:00, 306525.53it/s]\n"
     ]
    }
   ],
   "source": [
    "unique_products = []\n",
    "\n",
    "for lista in tqdm(products):\n",
    "    for product in lista:\n",
    "        if product not in unique_products:\n",
    "            unique_products.append(product)\n",
    "unique_products = sorted(unique_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "possibilities = [{\n",
    "    \"current\": product,\n",
    "    \"next\": next_product} for product, next_product in permutations(unique_products, 2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14042/14042 [00:34<00:00, 409.74it/s]\n"
     ]
    }
   ],
   "source": [
    "for pair in tqdm(possibilities):\n",
    "    pair[\"support_current\"] = sum([1 for p in products if pair[\"current\"] in p])/len(products)\n",
    "    pair[\"support_next\"] = sum([1 for p in products if pair[\"current\"] in p])/len(products)\n",
    "    pair[\"support_pair\"] = sum([1 for p in products if pair[\"current\"] in p and pair[\"next\"] in p])/len(products)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Confidence & Lift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14042/14042 [00:12<00:00, 1108.56it/s]\n"
     ]
    }
   ],
   "source": [
    "for pair in tqdm(possibilities):\n",
    "    new_proba = sum([1 for p in products if pair[\"current\"] in p and pair[\"next\"] in p])/len(products)\n",
    "    pair[\"confidence\"]= new_proba/pair[\"support_current\"]\n",
    "    pair[\"lift\"] = pair[\"confidence\"]/pair[\"support_next\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Developing class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rule():\n",
    "    \n",
    "    def __init__(self, product, bought_with, support, confidence, lift):\n",
    "        self.__product = product.title()\n",
    "        self.__bought_with = bought_with.title()\n",
    "        self.__support = support\n",
    "        self.__confidence = confidence\n",
    "        self.__lift = lift\n",
    "\n",
    "    def __str__(self):\n",
    "        text = f\">>> {self.__bought_with} and {self.__product} are both present in \"\n",
    "        text += f\"{100*self.__support:.2f}% of the transactions.\\nAmong people who bought {self.__product}, \"\n",
    "        text += f\"{100*self.__confidence:.2f}% also bought {self.__bought_with}.\\nThis means that people are \"\n",
    "        text += f\"{self.__lift:.2f} times more prone to buying {self.__bought_with} when they are \"\n",
    "        text += f\"buying {self.__product} as well.\"\n",
    "        return text\n",
    "    \n",
    "class APriori():\n",
    "    \n",
    "    def __init__(self, min_support, min_confidence, min_lift, min_length):\n",
    "        self.__min_support = min_support\n",
    "        self.__min_confidence = min_confidence\n",
    "        self.__min_lift = min_lift\n",
    "        self.__min_length = min_length\n",
    "        self.rules = []\n",
    "        \n",
    "    def _generate_list(self, df):\n",
    "        assert isinstance(df, pd.DataFrame), \"Insert a pandas dataframe\"\n",
    "        products = []\n",
    "        for i in range(df.shape[0]):\n",
    "            products.append([product.strip() for product in df.iloc[i, :].values if type(product)!=float])\n",
    "            \n",
    "        return products\n",
    "    \n",
    "    def _generate_combinations(self, products_list):\n",
    "        unique_products = []\n",
    "        for lista in products_list:\n",
    "            for product in lista:\n",
    "                if product not in unique_products:\n",
    "                    unique_products.append(product)\n",
    "        unique_products = sorted(unique_products)\n",
    "        \n",
    "        possibilities = [{\n",
    "                \"current\": product,\n",
    "                \"next\": next_product} for product, next_product in permutations(unique_products, 2)]\n",
    "        \n",
    "        return possibilities\n",
    "    \n",
    "    def _calculate_support_current(self, pair):\n",
    "        return sum([1 for p in products if pair[\"current\"] in p])/len(products)\n",
    "    \n",
    "    def _calculate_support_next(self, pair):\n",
    "        return sum([1 for p in products if pair[\"next\"] in p])/len(products)\n",
    "    \n",
    "    def _calculate_support_pair(self, pair):\n",
    "        return sum([1 for p in products if pair[\"current\"] in p and pair[\"next\"] in p])/len(products)\n",
    "\n",
    "    def _calculate_confidence(self, pair):\n",
    "        total = pair[\"support_current\"]*len(products)\n",
    "        return sum([1 for p in products if pair[\"current\"] in p and pair[\"next\"] in p])/total\n",
    "    \n",
    "    def _calculate_lift(self, pair):\n",
    "        return pair[\"confidence\"]/pair[\"support_next\"]\n",
    "    \n",
    "    def get_rules(self, df):\n",
    "        products_list = self._generate_list(df)\n",
    "        possibilities = self._generate_combinations(products_list)\n",
    "        \n",
    "        output = []\n",
    "\n",
    "        for pair in possibilities:\n",
    "            pair[\"support_current\"] = self._calculate_support_current(pair)\n",
    "            pair[\"support_next\"] = self._calculate_support_next(pair)\n",
    "            pair[\"support\"] = self._calculate_support_pair(pair)\n",
    "            if pair[\"support\"] < self.__min_support:\n",
    "                continue\n",
    "            pair[\"confidence\"] = self._calculate_confidence(pair)\n",
    "            if pair[\"confidence\"] < self.__min_confidence:\n",
    "                continue\n",
    "            pair[\"lift\"] = self._calculate_lift(pair)\n",
    "            if pair[\"lift\"] < self.__min_lift:\n",
    "                continue\n",
    "            output.append(pair)\n",
    "            \n",
    "        output = sorted(output, key=lambda x: -x[\"lift\"])\n",
    "        for o in output:\n",
    "            rule = Rule(product=o[\"current\"],\n",
    "                        bought_with=o[\"next\"],\n",
    "                        support=o[\"support\"],\n",
    "                        confidence=o[\"confidence\"],\n",
    "                        lift=o[\"lift\"]\n",
    "                    )\n",
    "            self.rules.append(rule)\n",
    "            \n",
    "        return output\n",
    "    \n",
    "    def get_highest_lifts(self, n_rules=10):\n",
    "        print(f\"########## {n_rules} Highest Lifts ##########\")\n",
    "        print()\n",
    "        for rule in self.rules:\n",
    "            print(rule)\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "apriori = APriori(min_support = 0.003, min_confidence = 0.2, min_lift = 3, min_length = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 39.7 s, sys: 181 ms, total: 39.9 s\n",
      "Wall time: 43.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = apriori.get_rules(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'current': 'fromage blanc',\n",
       "  'next': 'honey',\n",
       "  'support_current': 0.013598186908412212,\n",
       "  'support_next': 0.047460338621517134,\n",
       "  'support': 0.003332888948140248,\n",
       "  'confidence': 0.24509803921568626,\n",
       "  'lift': 5.164270764485569},\n",
       " {'current': 'light cream',\n",
       "  'next': 'chicken',\n",
       "  'support_current': 0.01559792027729636,\n",
       "  'support_next': 0.05999200106652446,\n",
       "  'support': 0.004532728969470737,\n",
       "  'confidence': 0.2905982905982906,\n",
       "  'lift': 4.8439506172839515},\n",
       " {'current': 'pasta',\n",
       "  'next': 'escalope',\n",
       "  'support_current': 0.01573123583522197,\n",
       "  'support_next': 0.0793227569657379,\n",
       "  'support': 0.005865884548726837,\n",
       "  'confidence': 0.3728813559322034,\n",
       "  'lift': 4.700811850163794},\n",
       " {'current': 'pasta',\n",
       "  'next': 'shrimp',\n",
       "  'support_current': 0.01573123583522197,\n",
       "  'support_next': 0.07145713904812692,\n",
       "  'support': 0.005065991201173177,\n",
       "  'confidence': 0.3220338983050847,\n",
       "  'lift': 4.506672147735896},\n",
       " {'current': 'whole wheat pasta',\n",
       "  'next': 'olive oil',\n",
       "  'support_current': 0.029462738301559793,\n",
       "  'support_next': 0.0658578856152513,\n",
       "  'support': 0.007998933475536596,\n",
       "  'confidence': 0.27149321266968324,\n",
       "  'lift': 4.1224100976422955}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## 10 Highest Lifts ##########\n",
      "\n",
      ">>> Honey and Fromage Blanc are both present in 0.33% of the transactions.\n",
      "Among people who bought Fromage Blanc, 24.51% also bought Honey.\n",
      "This means that people are 5.16 times more prone to buying Honey when they are buying Fromage Blanc as well.\n",
      "\n",
      ">>> Chicken and Light Cream are both present in 0.45% of the transactions.\n",
      "Among people who bought Light Cream, 29.06% also bought Chicken.\n",
      "This means that people are 4.84 times more prone to buying Chicken when they are buying Light Cream as well.\n",
      "\n",
      ">>> Escalope and Pasta are both present in 0.59% of the transactions.\n",
      "Among people who bought Pasta, 37.29% also bought Escalope.\n",
      "This means that people are 4.70 times more prone to buying Escalope when they are buying Pasta as well.\n",
      "\n",
      ">>> Shrimp and Pasta are both present in 0.51% of the transactions.\n",
      "Among people who bought Pasta, 32.20% also bought Shrimp.\n",
      "This means that people are 4.51 times more prone to buying Shrimp when they are buying Pasta as well.\n",
      "\n",
      ">>> Olive Oil and Whole Wheat Pasta are both present in 0.80% of the transactions.\n",
      "Among people who bought Whole Wheat Pasta, 27.15% also bought Olive Oil.\n",
      "This means that people are 4.12 times more prone to buying Olive Oil when they are buying Whole Wheat Pasta as well.\n",
      "\n",
      ">>> Ground Beef and Tomato Sauce are both present in 0.53% of the transactions.\n",
      "Among people who bought Tomato Sauce, 37.74% also bought Ground Beef.\n",
      "This means that people are 3.84 times more prone to buying Ground Beef when they are buying Tomato Sauce as well.\n",
      "\n",
      ">>> Escalope and Mushroom Cream Sauce are both present in 0.57% of the transactions.\n",
      "Among people who bought Mushroom Cream Sauce, 30.07% also bought Escalope.\n",
      "This means that people are 3.79 times more prone to buying Escalope when they are buying Mushroom Cream Sauce as well.\n",
      "\n",
      ">>> Ground Beef and Herb & Pepper are both present in 1.60% of the transactions.\n",
      "Among people who bought Herb & Pepper, 32.35% also bought Ground Beef.\n",
      "This means that people are 3.29 times more prone to buying Ground Beef when they are buying Herb & Pepper as well.\n",
      "\n",
      ">>> Olive Oil and Light Cream are both present in 0.32% of the transactions.\n",
      "Among people who bought Light Cream, 20.51% also bought Olive Oil.\n",
      "This means that people are 3.11 times more prone to buying Olive Oil when they are buying Light Cream as well.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "apriori.get_highest_lifts(n_rules=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
